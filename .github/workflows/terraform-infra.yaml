name: Terraform Infra Deploy/Destroy

on:
  workflow_dispatch:
    inputs:
      action:
        description: "Terraform action: apply or destroy"
        required: true
        default: "apply"
        type: choice
        options:
          - apply
          - destroy

jobs:
  terraform:
    runs-on: ubuntu-latest

    env:
      TF_LOG: INFO
      AWS_DEFAULT_REGION: ap-northeast-2

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-northeast-2

      - name: Terraform Init
        run: terraform init

      - name: Terraform Plan
        run: terraform plan

      - name: Terraform Apply or Destroy
        run: |
          if [ "${{ github.event.inputs.action }}" == "apply" ]; then
            terraform apply -auto-approve
          elif [ "${{ github.event.inputs.action }}" == "destroy" ]; then
            terraform destroy -auto-approve
          else
            echo "Invalid action input. Use apply or destroy."
            exit 1
          fi

      - name: Get Terraform Outputs
        if: ${{ github.event.inputs.action == 'apply' }}
        run: |
          echo "EKS_CLUSTER_NAME=$(terraform output -raw eks_cluster_name)" >> $GITHUB_ENV
          echo "NODE_ROLE_ARN=$(terraform output -raw node_role_arn)" >> $GITHUB_ENV

      - name: Wait for EKS Cluster to be ACTIVE
        if: ${{ github.event.inputs.action == 'apply' }}
        run: |
          for i in {1..30}; do
            STATUS=$(aws eks describe-cluster \
              --region ap-northeast-2 \
              --name ${{ env.EKS_CLUSTER_NAME }} \
              --query "cluster.status" --output text)

            echo "EKS status: $STATUS"
            if [ "$STATUS" = "ACTIVE" ]; then
              break
            fi
            echo "Waiting for EKS to become ACTIVE..."
            sleep 10
          done
        
      - name: Install eksctl
        if: ${{ github.event.inputs.action == 'apply' }}
        run: |
          curl --silent --location "https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_Linux_amd64.tar.gz" | tar xz -C /tmp
          sudo mv /tmp/eksctl /usr/local/bin


      - name: Associate OIDC Provider (for IRSA)
        if: ${{ github.event.inputs.action == 'apply' }}
        run: |
          eksctl utils associate-iam-oidc-provider \
            --region ap-northeast-2 \
            --cluster ${{ env.EKS_CLUSTER_NAME }} \
            --approve


      - name: Install kubectl
        if: ${{ github.event.inputs.action == 'apply' }}
        uses: azure/setup-kubectl@v3
        with:
          version: "v1.28.0"

      - name: Configure kubectl for EKS
        if: ${{ github.event.inputs.action == 'apply' }}
        run: |
          aws eks update-kubeconfig \
            --region ap-northeast-2 \
            --name ${{ env.EKS_CLUSTER_NAME }}

      - name: Apply aws-auth ConfigMap dynamically
        if: ${{ github.event.inputs.action == 'apply' }}
        run: |
          echo "apiVersion: v1" > aws-auth.yaml
          echo "kind: ConfigMap" >> aws-auth.yaml
          echo "metadata:" >> aws-auth.yaml
          echo "  name: aws-auth" >> aws-auth.yaml
          echo "  namespace: kube-system" >> aws-auth.yaml
          echo "data:" >> aws-auth.yaml
          echo "  mapRoles: |" >> aws-auth.yaml
          echo "    - rolearn: ${{ env.NODE_ROLE_ARN }}" >> aws-auth.yaml
          echo "      username: system:node:{{EC2PrivateDNSName}}" >> aws-auth.yaml
          echo "      groups:" >> aws-auth.yaml
          echo "        - system:bootstrappers" >> aws-auth.yaml
          echo "        - system:nodes" >> aws-auth.yaml
          echo "  mapUsers: |" >> aws-auth.yaml
          echo "    - userarn: arn:aws:iam::863676520919:user/mapweather" >> aws-auth.yaml
          echo "      username: mapweather" >> aws-auth.yaml
          echo "      groups:" >> aws-auth.yaml
          echo '        - "system:masters"' >> aws-auth.yaml
          echo "    - userarn: arn:aws:iam::863676520919:root" >> aws-auth.yaml
          echo "      username: root" >> aws-auth.yaml
          echo "      groups:" >> aws-auth.yaml          
          echo '        - "system:masters"' >> aws-auth.yaml

          kubectl apply -f aws-auth.yaml || exit 1
      # âœ… CoreDNS ì¤€ë¹„ ìƒíƒœ ëŒ€ê¸°
      - name: Wait for CoreDNS to be Ready
        if: ${{ github.event.inputs.action == 'apply' }}
        run: |
          echo "ğŸ” CoreDNS ìƒíƒœ í™•ì¸ ì¤‘..."
          kubectl get pods -n kube-system -l k8s-app=kube-dns -o wide
          echo "â³ CoreDNS Deployment ì¤€ë¹„ ìƒíƒœ ëŒ€ê¸° ì¤‘..."
          kubectl rollout status deployment/coredns -n kube-system --timeout=120s
          echo "âœ… CoreDNS ì¤€ë¹„ ì™„ë£Œë¨."

      # âœ… CoreDNS ë°°í¬ë¥¼ ë‘ ë…¸ë“œì— ë¶„ì‚°ë˜ë„ë¡ patch
      - name: Patch CoreDNS with topologySpreadConstraints
        if: ${{ github.event.inputs.action == 'apply' }}
        run: |
          echo "ğŸ”§ CoreDNSì— topologySpreadConstraints íŒ¨ì¹˜ ì¤‘..."
          kubectl patch deployment coredns -n kube-system --type='merge' -p '{
            "spec": {
              "template": {
                "spec": {
                  "topologySpreadConstraints": [{
                    "maxSkew": 1,
                    "topologyKey": "kubernetes.io/hostname",
                    "whenUnsatisfiable": "DoNotSchedule",
                    "labelSelector": {
                      "matchLabels": {
                        "k8s-app": "kube-dns"
                      }
                    }
                  }]
                }
              } 
            }
          }'
          echo "âœ… CoreDNS ë¶„ì‚° ë°°í¬ ì„¤ì • ì™„ë£Œë¨."

      - name: Restart CoreDNS to Apply Spread Constraints
        if: ${{ github.event.inputs.action == 'apply' }}
        run: |
          echo "ğŸ” CoreDNS Deployment ì¬ì‹œì‘ ì¤‘..."
          kubectl rollout restart deployment/coredns -n kube-system
          echo "â³ CoreDNS ìƒíƒœ ëŒ€ê¸° ì¤‘..."
          kubectl rollout status deployment/coredns -n kube-system --timeout=120s
          echo "âœ… CoreDNS ì¬ì‹œì‘ ë° ë¶„ì‚° ì ìš© ì™„ë£Œë¨."


      # âœ… CoreDNS ì „ì²´ ë¡œê·¸ ìˆ˜ì§‘
      - name: Collect CoreDNS Logs
        if: ${{ github.event.inputs.action == 'apply' }}
        run: |
          echo "ğŸ“¦ CoreDNS ë¡œê·¸ ìˆ˜ì§‘ ì‹œì‘..."
          mkdir -p logs
          for pod in $(kubectl get pods -n kube-system -l k8s-app=kube-dns -o jsonpath="{.items[*].metadata.name}"); do
            echo "ğŸ” $pod ë¡œê·¸ ìˆ˜ì§‘ ì¤‘..."
            kubectl logs -n kube-system $pod > logs/${pod}_current.log || echo "âš ï¸ í˜„ì¬ ë¡œê·¸ ìˆ˜ì§‘ ì‹¤íŒ¨"
            kubectl logs -n kube-system $pod --previous > logs/${pod}_previous.log || echo "âš ï¸ ì´ì „ ë¡œê·¸ ì—†ìŒ (Crash ì—†ì—ˆì„ ê°€ëŠ¥ì„±)"
          done
          echo "âœ… ë¡œê·¸ ìˆ˜ì§‘ ì™„ë£Œ"

      # âœ… GitHub Actions Artifactsë¡œ ë¡œê·¸ ì—…ë¡œë“œ
      - name: Upload CoreDNS Logs to Artifacts
        if: ${{ github.event.inputs.action == 'apply' }}
        uses: actions/upload-artifact@v4
        with:
          name: coredns-logs
          path: logs/
